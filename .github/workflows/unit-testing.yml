name: Unit Tests
on: [ pull_request, workflow_dispatch ]
jobs:
  build-and-test:
    runs-on: macos-14
    permissions:
      contents: write
      pull-requests: write
      pages: write
      id-token: write
    steps:
      - name: Set up Xcode 16.2
        uses: maxim-lobanov/setup-xcode@v1
        with:
          xcode-version: '16.2'

      - name: Verify Xcode Version
        run: xcodebuild -version
        
      - name: Checkout main repo and submodules
        uses: actions/checkout@v3
        with:
          submodules: true
          token: ${{ secrets.CI_GITHUB_ACCESS_TOKEN }}
          
      - name: Cache Swift packages
        uses: actions/cache@v4
        with:
          path: |
            .build
            SourcePackages
            ~/Library/Developer/Xcode/DerivedData/**/SourcePackages
          key: ${{ runner.os }}-spm-${{ hashFiles('**/Package.resolved') }}
          restore-keys: |
            ${{ runner.os }}-spm-
            
      - name: Cache Xcode DerivedData
        uses: actions/cache@v4
        with:
          path: ~/Library/Developer/Xcode/DerivedData
          key: ${{ runner.os }}-deriveddata-${{ hashFiles('**/*.xcodeproj/project.pbxproj') }}
          restore-keys: |
            ${{ runner.os }}-deriveddata-
            
      - name: Cache Test History
        uses: actions/cache@v4
        with:
          path: .test-history
          key: test-history-${{ github.head_ref || github.ref_name }}-${{ github.run_number }}
          restore-keys: |
            test-history-${{ github.head_ref || github.ref_name }}-
            test-history-develop-
            test-history-
            
      - name: Checkout Certificates
        uses: actions/checkout@v3
        with:
          repository: ThePalaceProject/mobile-certificates
          token: ${{ secrets.CI_GITHUB_ACCESS_TOKEN }}
          path: ./mobile-certificates
          
      - name: Checkout Adobe RMSDK
        uses: ./.github/actions/checkout-adobe
        with:
          token: ${{ secrets.CI_GITHUB_ACCESS_TOKEN }}
          
      - name: Setup repo with DRM
        run: ./scripts/setup-repo-drm.sh
        env:
          BUILD_CONTEXT: ci
          
      - name: Build non-Carthage 3rd party dependencies
        run: ./scripts/build-3rd-party-dependencies.sh
        env:
          BUILD_CONTEXT: ci
          
      - name: List available simulators for debugging
        run: xcrun simctl list devices available | grep iPhone | head -10
        
      - name: Run Palace unit tests
        id: tests
        timeout-minutes: 20
        run: ./scripts/xcode-test-optimized.sh
        env:
          BUILD_CONTEXT: ci
        continue-on-error: true
          
      - name: Find Test Results
        if: always()
        id: find_results
        run: |
          echo "Looking for xcresult bundles..."
          echo "Current directory: $(pwd)"
          echo "Directory contents:"
          ls -la | head -20
          
          # Check for Palace tests result
          if [ -d "TestResults.xcresult" ]; then
            echo "‚úÖ Found Palace tests: ./TestResults.xcresult"
            echo "xcresult size: $(du -sh TestResults.xcresult)"
            echo "path=TestResults.xcresult" >> $GITHUB_OUTPUT
            echo "found=true" >> $GITHUB_OUTPUT
            
            # Quick check of what's inside
            echo "=== Quick xcresult summary ==="
            xcrun xcresulttool get test-results summary --path TestResults.xcresult 2>&1 | head -30 || echo "Could not get summary"
          else
            echo "path=" >> $GITHUB_OUTPUT
            echo "found=false" >> $GITHUB_OUTPUT
          fi
          
          # Search in DerivedData if not found
          if [ "${{ steps.find_results.outputs.found }}" != "true" ]; then
            echo "Searching in DerivedData..."
            FOUND=$(find ~/Library/Developer/Xcode/DerivedData -name "*.xcresult" -type d 2>/dev/null | head -1)
            if [ -n "$FOUND" ]; then
              echo "‚úÖ Found in DerivedData: $FOUND"
              cp -r "$FOUND" ./TestResults.xcresult
              echo "path=TestResults.xcresult" >> $GITHUB_OUTPUT
              echo "found=true" >> $GITHUB_OUTPUT
            fi
          fi
          
      - name: Parse Test Results
        if: always()
        id: parse_results
        run: |
          RESULT_PATH="${{ steps.find_results.outputs.path }}"
          
          # Initialize defaults
          echo "tests=0" >> $GITHUB_OUTPUT
          echo "passed=0" >> $GITHUB_OUTPUT
          echo "failed=0" >> $GITHUB_OUTPUT
          echo "skipped=0" >> $GITHUB_OUTPUT
          echo "duration=unknown" >> $GITHUB_OUTPUT
          echo "pass_rate=N/A" >> $GITHUB_OUTPUT
          
          # Parse Palace tests
          if [ "${{ steps.find_results.outputs.found }}" == "true" ] && [ -d "$RESULT_PATH" ]; then
            echo "Parsing Palace test results from: $RESULT_PATH"
            
            echo "=== xcresulttool version ==="
            xcrun xcresulttool version 2>/dev/null || echo "version command not available"
            
            echo "=== Raw test-results summary (first 2000 chars) ==="
            xcrun xcresulttool get test-results summary --path "$RESULT_PATH" 2>/dev/null | head -c 2000 || echo "summary command failed"
            
            echo ""
            echo "=== Parsing with Python script ==="
            python3 scripts/parse-xcresult.py "$RESULT_PATH" --json test-data.json || true
            
            echo "=== Parsed Palace Test Results ==="
            cat test-data.json | python3 -c "import json,sys; d=json.load(sys.stdin); s=d.get('summary',{}); print(f\"Tests: {s.get('tests',0)}, Passed: {s.get('passed',0)}, Failed: {s.get('failed',0)}\")" 2>/dev/null || echo "Could not read test-data.json"
          else
            echo "No Palace results to parse"
          fi
          
      - name: Compare with History
        if: always()
        id: history
        run: |
          if [ -f "test-data.json" ] && [ -d ".test-history" ]; then
            echo "Comparing with test history..."
            python3 scripts/test-history.py compare test-data.json .test-history || true
          else
            echo "No history available for comparison"
            echo "has_history=false" >> $GITHUB_OUTPUT
          fi
          
      - name: Save to History
        if: always()
        run: |
          if [ -f "test-data.json" ]; then
            python3 scripts/test-history.py save test-data.json .test-history || true
          fi
          
      - name: Parse Code Coverage
        if: always()
        id: coverage
        run: |
          RESULT_PATH="${{ steps.find_results.outputs.path }}"
          
          # Initialize defaults
          echo "coverage=0" >> $GITHUB_OUTPUT
          echo "coverage_formatted=N/A" >> $GITHUB_OUTPUT
          
          if [ "${{ steps.find_results.outputs.found }}" != "true" ] || [ ! -d "$RESULT_PATH" ]; then
            echo "No results for coverage"
            exit 0
          fi
          
          echo "Extracting code coverage..."
          python3 scripts/coverage-report.py "$RESULT_PATH" --json coverage-data.json || true
          
      - name: Collect Snapshot Failures
        if: always()
        id: snapshots
        run: |
          mkdir -p snapshot-failures
          
          echo "Searching for snapshot failures..."
          
          # Search multiple locations
          find /Users/runner/Library/Developer/CoreSimulator -name "*.png" -path "*tmp*" -type f 2>/dev/null | head -50 | while read -r file; do
            cp "$file" snapshot-failures/ 2>/dev/null || true
          done
          
          find ~/Library/Developer/Xcode/DerivedData -name "*.png" -path "*Failures*" -type f 2>/dev/null | head -50 | while read -r file; do
            cp "$file" snapshot-failures/ 2>/dev/null || true
          done
          
          # Count what we found
          COUNT=$(ls -1 snapshot-failures/*.png 2>/dev/null | wc -l | tr -d ' ')
          echo "Total snapshot files found: $COUNT"
          
          if [ "$COUNT" -gt "0" ]; then
            echo "found=true" >> $GITHUB_OUTPUT
            echo "count=$COUNT" >> $GITHUB_OUTPUT
            
            # Process snapshots to generate viewer and comparisons
            python3 scripts/process-snapshots.py snapshot-failures || true
          else
            echo "found=false" >> $GITHUB_OUTPUT
            echo "count=0" >> $GITHUB_OUTPUT
          fi
          
      - name: Generate Test Reports
        if: always()
        run: |
          mkdir -p test-report
          
          # Generate Markdown report
          python3 scripts/generate-test-report.py test-data.json test-report/TEST_RESULTS.md \
            --commit "${{ github.sha }}" \
            --branch "${{ github.head_ref || github.ref_name }}" \
            --snapshot-count "${{ steps.snapshots.outputs.count }}" || true
          
          # Generate HTML report
          python3 scripts/generate-html-report.py test-data.json test-report/test-report.html \
            --coverage coverage-data.json \
            --commit "${{ github.sha }}" \
            --branch "${{ github.head_ref || github.ref_name }}" || true
          
          # Fallback if scripts fail
          if [ ! -f "test-report/TEST_RESULTS.md" ]; then
            echo "# Test Results" > test-report/TEST_RESULTS.md
            echo "" >> test-report/TEST_RESULTS.md
            echo "Tests: ${{ steps.parse_results.outputs.tests }}" >> test-report/TEST_RESULTS.md
            echo "Passed: ${{ steps.parse_results.outputs.passed }}" >> test-report/TEST_RESULTS.md
            echo "Failed: ${{ steps.parse_results.outputs.failed }}" >> test-report/TEST_RESULTS.md
          fi
          
          echo "Generated reports:"
          ls -la test-report/
          
      - name: Generate GitHub Step Summary
        if: always()
        run: |
          TESTS="${{ steps.parse_results.outputs.tests }}"
          PASSED="${{ steps.parse_results.outputs.passed }}"
          FAILED="${{ steps.parse_results.outputs.failed }}"
          SKIPPED="${{ steps.parse_results.outputs.skipped }}"
          DURATION="${{ steps.parse_results.outputs.duration }}"
          PASS_RATE="${{ steps.parse_results.outputs.pass_rate }}"
          CLASS_SUMMARY="${{ steps.parse_results.outputs.class_summary }}"
          COVERAGE="${{ steps.coverage.outputs.coverage_formatted }}"
          COVERAGE_TARGETS="${{ steps.coverage.outputs.coverage_targets }}"
          NEW_FAILURES="${{ steps.history.outputs.new_failures }}"
          FIXED_TESTS="${{ steps.history.outputs.fixed_tests }}"
          FLAKY_TESTS="${{ steps.history.outputs.flaky_tests }}"
          TEST_COUNT_CHANGE="${{ steps.history.outputs.test_count_change }}"
          BUILD_STATUS="${{ steps.parse_results.outputs.build_status }}"
          BUILD_ERRORS="${{ steps.parse_results.outputs.build_errors }}"
          
          echo "## üß™ Palace Unit Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check for build failure first
          if [ "$BUILD_STATUS" = "failed" ]; then
            echo "### üî¥ BUILD FAILED" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The build failed before tests could run." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            if [ -n "$BUILD_ERRORS" ]; then
              echo "<details>" >> $GITHUB_STEP_SUMMARY
              echo "<summary><strong>Build Errors</strong></summary>" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "$BUILD_ERRORS" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "</details>" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
          elif [ "$TESTS" != "0" ] && [ "$TESTS" != "" ]; then
            # Header with counts
            if [ "$FAILED" = "0" ]; then
              echo "### ‚úÖ ALL TESTS PASSED" >> $GITHUB_STEP_SUMMARY
            else
              echo "### ‚ùå $FAILED TEST(S) FAILED" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Quick stats line
            COVERAGE_DISPLAY=""
            if [ "$COVERAGE" != "N/A" ] && [ -n "$COVERAGE" ]; then
              COVERAGE_DISPLAY=" | üìà $COVERAGE coverage"
            fi
            echo "**$TESTS tests** | **$PASSED passed** | **$FAILED failed** | **$SKIPPED skipped** | ‚è±Ô∏è $DURATION | üìä $PASS_RATE$COVERAGE_DISPLAY" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Class breakdown table
            if [ -n "$CLASS_SUMMARY" ]; then
              echo "### Tests by Class" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "| Class | Tests | Passed | Failed | Duration |" >> $GITHUB_STEP_SUMMARY
              echo "|-------|-------|--------|--------|----------|" >> $GITHUB_STEP_SUMMARY
              echo "$CLASS_SUMMARY" | while IFS='|' read -r class total passed failed duration; do
                if [ "$failed" = "0" ]; then
                  echo "| ‚úÖ $class | $total | $passed | $failed | $duration |" >> $GITHUB_STEP_SUMMARY
                else
                  echo "| ‚ùå $class | $total | $passed | **$failed** | $duration |" >> $GITHUB_STEP_SUMMARY
                fi
              done
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
          else
            # 0 tests - check why
            if [ "${{ steps.tests.outcome }}" = "success" ]; then
              echo "### ‚úÖ ALL TESTS PASSED" >> $GITHUB_STEP_SUMMARY
            elif [ "$BUILD_STATUS" = "failed" ] || [ -n "$BUILD_ERRORS" ]; then
              echo "### üî¥ BUILD FAILED - No tests ran" >> $GITHUB_STEP_SUMMARY
              if [ -n "$BUILD_ERRORS" ]; then
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "<details>" >> $GITHUB_STEP_SUMMARY
                echo "<summary><strong>Build Errors</strong></summary>" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                echo '```' >> $GITHUB_STEP_SUMMARY
                echo "$BUILD_ERRORS" >> $GITHUB_STEP_SUMMARY
                echo '```' >> $GITHUB_STEP_SUMMARY
                echo "</details>" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "### ‚ùå TESTS FAILED" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          # Failed tests
          FAILED_TESTS="${{ steps.parse_results.outputs.failed_tests }}"
          if [ -n "$FAILED_TESTS" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "<details>" >> $GITHUB_STEP_SUMMARY
            echo "<summary><strong>Failed Tests</strong></summary>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "$FAILED_TESTS" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "</details>" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Code Coverage
          if [ "$COVERAGE" != "N/A" ] && [ -n "$COVERAGE" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üìà Code Coverage: $COVERAGE" >> $GITHUB_STEP_SUMMARY
            if [ -n "$COVERAGE_TARGETS" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "| Target | Coverage |" >> $GITHUB_STEP_SUMMARY
              echo "|--------|----------|" >> $GITHUB_STEP_SUMMARY
              echo "$COVERAGE_TARGETS" | while IFS='|' read -r name cov covered total; do
                if [ -n "$name" ]; then
                  echo "| $name | $cov |" >> $GITHUB_STEP_SUMMARY
                fi
              done
            fi
          fi
          
          # History/Trends
          if [ -n "$NEW_FAILURES" ] || [ -n "$FIXED_TESTS" ] || [ -n "$FLAKY_TESTS" ] || [ -n "$TEST_COUNT_CHANGE" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üìà Trends" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            if [ -n "$TEST_COUNT_CHANGE" ]; then
              echo "Test count change: **$TEST_COUNT_CHANGE**" >> $GITHUB_STEP_SUMMARY
            fi
            
            if [ -n "$NEW_FAILURES" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "<details>" >> $GITHUB_STEP_SUMMARY
              echo "<summary>‚ö†Ô∏è <strong>New Failures</strong></summary>" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "$NEW_FAILURES" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "</details>" >> $GITHUB_STEP_SUMMARY
            fi
            
            if [ -n "$FIXED_TESTS" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "<details>" >> $GITHUB_STEP_SUMMARY
              echo "<summary>‚úÖ <strong>Fixed Tests</strong></summary>" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "$FIXED_TESTS" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "</details>" >> $GITHUB_STEP_SUMMARY
            fi
            
            if [ -n "$FLAKY_TESTS" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "<details>" >> $GITHUB_STEP_SUMMARY
              echo "<summary>‚ö° <strong>Flaky Tests Detected</strong></summary>" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "$FLAKY_TESTS" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "</details>" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          # Snapshots
          SNAPSHOT_COUNT="${{ steps.snapshots.outputs.count }}"
          if [ "$SNAPSHOT_COUNT" != "0" ] && [ -n "$SNAPSHOT_COUNT" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üì∏ Snapshot Failures: $SNAPSHOT_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "Download **snapshot-failures** artifact to view diff images" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Report Link and Artifacts
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          
          REPORT_URL="${{ steps.deploy_report.outputs.report_url }}"
          if [ -n "$REPORT_URL" ]; then
            echo "### üîó [View Interactive Report]($REPORT_URL)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "### üì¶ Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Artifact | Description |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|" >> $GITHUB_STEP_SUMMARY
          echo "| **test-report** | üìÑ Markdown + HTML report |" >> $GITHUB_STEP_SUMMARY
          echo "| **test-data** | üìä JSON data files |" >> $GITHUB_STEP_SUMMARY
          echo "| **test-results** | üîç Full xcresult (open in Xcode) |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.snapshots.outputs.found }}" = "true" ]; then
            echo "| **snapshot-failures** | üñºÔ∏è Visual diff images |" >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Upload Test Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-report
          path: test-report/
          retention-days: 14
          if-no-files-found: ignore
          
      - name: Upload Test Data JSON
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-data
          path: |
            test-data.json
            coverage-data.json
          retention-days: 14
          if-no-files-found: ignore
          
      - name: Upload Snapshot Failures
        if: steps.snapshots.outputs.found == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: snapshot-failures
          path: snapshot-failures/
          retention-days: 14
          if-no-files-found: ignore
          
      - name: Upload Test Results
        if: steps.find_results.outputs.found == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: ${{ steps.find_results.outputs.path }}
          retention-days: 14
          if-no-files-found: ignore
          
      - name: Deploy Report to GitHub Pages
        if: always()
        id: deploy_report
        run: |
          # Create report directory structure
          REPORT_DIR="test-reports/${{ github.run_number }}"
          mkdir -p "$REPORT_DIR"
          
          # Copy reports
          cp test-report/test-report.html "$REPORT_DIR/" 2>/dev/null || true
          cp test-report/TEST_RESULTS.md "$REPORT_DIR/" 2>/dev/null || true
          cp test-data.json "$REPORT_DIR/" 2>/dev/null || true
          cp coverage-data.json "$REPORT_DIR/" 2>/dev/null || true
          
          # Copy snapshot viewer if exists
          if [ -f "snapshot-failures/snapshot-viewer.html" ]; then
            cp snapshot-failures/snapshot-viewer.html "$REPORT_DIR/"
            cp snapshot-failures/*.png "$REPORT_DIR/" 2>/dev/null || true
          fi
          
          # Create index.html that redirects to the report
          cat > "$REPORT_DIR/index.html" << 'INDEXEOF'
          <!DOCTYPE html>
          <html>
          <head>
            <meta http-equiv="refresh" content="0; url=test-report.html">
            <title>Redirecting to Test Report</title>
          </head>
          <body>
            <p>Redirecting to <a href="test-report.html">Test Report</a>...</p>
          </body>
          </html>
          INDEXEOF
          
          # Create root index listing recent reports
          mkdir -p test-reports
          cat > test-reports/index.html << 'ROOTINDEXEOF'
          <!DOCTYPE html>
          <html>
          <head>
            <title>Palace iOS Test Reports</title>
            <style>
              body { font-family: -apple-system, sans-serif; max-width: 800px; margin: 50px auto; padding: 20px; background: #0d1117; color: #f0f6fc; }
              h1 { color: #58a6ff; }
              a { color: #58a6ff; }
              .report-link { display: block; padding: 10px; margin: 5px 0; background: #161b22; border-radius: 6px; text-decoration: none; }
              .report-link:hover { background: #21262d; }
            </style>
          </head>
          <body>
            <h1>üß™ Palace iOS Test Reports</h1>
            <p>Recent test reports from CI runs:</p>
            <div id="reports"></div>
            <script>
              // This will be populated by the actual report links
              document.getElementById('reports').innerHTML = '<p>Browse to a specific run number: <code>/test-reports/{run-number}/</code></p>';
            </script>
          </body>
          </html>
          ROOTINDEXEOF
          
          # Output the report URL
          REPO_NAME="${GITHUB_REPOSITORY#*/}"
          REPO_OWNER="${GITHUB_REPOSITORY%/*}"
          REPORT_URL="https://${REPO_OWNER}.github.io/${REPO_NAME}/test-reports/${{ github.run_number }}/"
          echo "report_url=$REPORT_URL" >> $GITHUB_OUTPUT
          echo "Report will be available at: $REPORT_URL"
          
      - name: Publish to GitHub Pages
        if: always()
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./test-reports
          destination_dir: test-reports
          keep_files: true
          
      - name: Post PR Comment with Results
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            const tests = '${{ steps.parse_results.outputs.tests }}';
            const passed = '${{ steps.parse_results.outputs.passed }}';
            const failed = '${{ steps.parse_results.outputs.failed }}';
            const skipped = '${{ steps.parse_results.outputs.skipped }}';
            const duration = '${{ steps.parse_results.outputs.duration }}';
            const passRate = '${{ steps.parse_results.outputs.pass_rate }}';
            const testOutcome = '${{ steps.tests.outcome }}';
            const failedTests = `${{ steps.parse_results.outputs.failed_tests }}`;
            const classSummary = `${{ steps.parse_results.outputs.class_summary }}`;
            const snapshotCount = '${{ steps.snapshots.outputs.count }}';
            const coverage = '${{ steps.coverage.outputs.coverage_formatted }}';
            const coverageTargets = `${{ steps.coverage.outputs.coverage_targets }}`;
            const newFailures = `${{ steps.history.outputs.new_failures }}`;
            const fixedTests = `${{ steps.history.outputs.fixed_tests }}`;
            const flakyTests = `${{ steps.history.outputs.flaky_tests }}`;
            const testCountChange = '${{ steps.history.outputs.test_count_change }}';
            const buildStatus = '${{ steps.parse_results.outputs.build_status }}';
            const buildErrors = `${{ steps.parse_results.outputs.build_errors }}`;
            const runUrl = `${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID}`;
            const reportUrl = '${{ steps.deploy_report.outputs.report_url }}';
            
            let body = '## üß™ Unit Test Results\n\n';
            
            // Add clickable report link at the top
            if (reportUrl) {
              body += `üìä **[View Full Interactive Report](${reportUrl})**\n\n`;
            }
            
            // Check for build failure first
            if (buildStatus === 'failed') {
              body += `### üî¥ BUILD FAILED\n\n`;
              body += `The build failed before tests could run.\n\n`;
              
              if (buildErrors && buildErrors.trim()) {
                body += `<details>\n<summary><strong>Build Errors</strong></summary>\n\n`;
                body += '```\n' + buildErrors.trim() + '\n```\n';
                body += `</details>\n\n`;
              }
            } else if (tests !== '0' && tests !== '') {
              // Status header
              if (failed === '0') {
                body += `### ‚úÖ ALL TESTS PASSED\n\n`;
              } else {
                body += `### ‚ùå ${failed} TEST${failed === '1' ? '' : 'S'} FAILED\n\n`;
              }
              
              // Quick stats
              let coverageDisplay = '';
              if (coverage && coverage !== 'N/A' && coverage !== '') {
                coverageDisplay = ` | üìà ${coverage} coverage`;
              }
              body += `**${tests} tests** | **${passed} passed** | **${failed} failed** | **${skipped} skipped** | ‚è±Ô∏è ${duration} | üìä ${passRate}${coverageDisplay}\n\n`;
              
              // Class breakdown table
              if (classSummary && classSummary.trim()) {
                body += `### Tests by Class\n\n`;
                body += `| Class | Tests | Passed | Failed | Duration |\n`;
                body += `|-------|-------|--------|--------|----------|\n`;
                classSummary.trim().split('\n').forEach(line => {
                  const [cls, total, pass, fail, dur] = line.split('|');
                  if (cls) {
                    const icon = fail === '0' ? '‚úÖ' : '‚ùå';
                    const failCell = fail === '0' ? fail : `**${fail}**`;
                    body += `| ${icon} ${cls} | ${total} | ${pass} | ${failCell} | ${dur} |\n`;
                  }
                });
                body += '\n';
              }
            } else {
              if (testOutcome === 'success') {
                body += `### ‚úÖ ALL TESTS PASSED\n\n`;
              } else if (buildErrors && buildErrors.trim()) {
                body += `### üî¥ BUILD FAILED - No tests ran\n\n`;
                body += `<details>\n<summary><strong>Build Errors</strong></summary>\n\n`;
                body += '```\n' + buildErrors.trim() + '\n```\n';
                body += `</details>\n\n`;
              } else {
                body += `### ‚ùå TESTS FAILED\n\n`;
              }
            }
            
            // Failed tests details
            if (failedTests && failedTests.trim()) {
              body += `<details>\n<summary><strong>Failed Tests (click to expand)</strong></summary>\n\n`;
              body += '```\n' + failedTests.trim() + '\n```\n';
              body += `</details>\n\n`;
            }
            
            // Code Coverage
            if (coverage && coverage !== 'N/A' && coverage !== '') {
              body += `### üìà Code Coverage: ${coverage}\n\n`;
              if (coverageTargets && coverageTargets.trim()) {
                body += `| Target | Coverage |\n`;
                body += `|--------|----------|\n`;
                coverageTargets.trim().split('\n').forEach(line => {
                  const [name, cov] = line.split('|');
                  if (name) {
                    body += `| ${name} | ${cov} |\n`;
                  }
                });
                body += '\n';
              }
            }
            
            // Trends
            if (newFailures || fixedTests || flakyTests || testCountChange) {
              body += `### üìà Trends\n\n`;
              
              if (testCountChange) {
                body += `Test count change: **${testCountChange}**\n\n`;
              }
              
              if (newFailures && newFailures.trim()) {
                body += `<details>\n<summary>‚ö†Ô∏è <strong>New Failures</strong></summary>\n\n`;
                body += '```\n' + newFailures.trim() + '\n```\n';
                body += `</details>\n\n`;
              }
              
              if (fixedTests && fixedTests.trim()) {
                body += `<details>\n<summary>‚úÖ <strong>Fixed Tests</strong></summary>\n\n`;
                body += '```\n' + fixedTests.trim() + '\n```\n';
                body += `</details>\n\n`;
              }
              
              if (flakyTests && flakyTests.trim()) {
                body += `<details>\n<summary>‚ö° <strong>Flaky Tests Detected</strong></summary>\n\n`;
                body += '```\n' + flakyTests.trim() + '\n```\n';
                body += `</details>\n\n`;
              }
            }
            
            // Snapshot failures
            if (snapshotCount && snapshotCount !== '0') {
              body += `### üì∏ Snapshot Failures: ${snapshotCount}\n`;
              body += `Download the **snapshot-failures** artifact to view visual differences.\n\n`;
            }
            
            // Links section
            body += `---\n`;
            if (reportUrl) {
              body += `üîó **[Interactive HTML Report](${reportUrl})** | `;
            }
            body += `**[CI Run Details](${runUrl})**\n\n`;
            
            // Artifacts table
            body += `<details>\n<summary>üì¶ <strong>Downloadable Artifacts</strong></summary>\n\n`;
            body += `| Artifact | Description |\n`;
            body += `|----------|-------------|\n`;
            body += `| test-report | üìÑ Markdown + HTML reports |\n`;
            body += `| test-data | üìä JSON data for tooling |\n`;
            body += `| test-results | üîç Full xcresult (open in Xcode) |\n`;
            if (snapshotCount && snapshotCount !== '0') {
              body += `| snapshot-failures | üñºÔ∏è Visual diff images |\n`;
            }
            body += `\n</details>`;
            
            // Find and update or create comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });
            
            const botComment = comments.find(c => 
              c.user.type === 'Bot' && 
              c.body.includes('üß™ Unit Test Results')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }
          
      - name: Fail if tests failed
        if: steps.tests.outcome == 'failure'
        run: exit 1
