name: Unit Tests
on: [ pull_request, workflow_dispatch ]
jobs:
  build-and-test:
    runs-on: macos-14
    permissions:
      contents: read
      pull-requests: write
    steps:
      - name: Set up Xcode 16.2
        uses: maxim-lobanov/setup-xcode@v1
        with:
          xcode-version: '16.2'

      - name: Verify Xcode Version
        run: xcodebuild -version
        
      - name: Checkout main repo and submodules
        uses: actions/checkout@v3
        with:
          submodules: true
          token: ${{ secrets.CI_GITHUB_ACCESS_TOKEN }}
          
      - name: Cache Swift packages
        uses: actions/cache@v4
        with:
          path: |
            .build
            SourcePackages
            ~/Library/Developer/Xcode/DerivedData/**/SourcePackages
          key: ${{ runner.os }}-spm-${{ hashFiles('**/Package.resolved') }}
          restore-keys: |
            ${{ runner.os }}-spm-
            
      - name: Cache Xcode DerivedData
        uses: actions/cache@v4
        with:
          path: ~/Library/Developer/Xcode/DerivedData
          key: ${{ runner.os }}-deriveddata-${{ hashFiles('**/*.xcodeproj/project.pbxproj') }}
          restore-keys: |
            ${{ runner.os }}-deriveddata-
            
      - name: Checkout Certificates
        uses: actions/checkout@v3
        with:
          repository: ThePalaceProject/mobile-certificates
          token: ${{ secrets.CI_GITHUB_ACCESS_TOKEN }}
          path: ./mobile-certificates
          
      - name: Checkout Adobe RMSDK
        uses: ./.github/actions/checkout-adobe
        with:
          token: ${{ secrets.CI_GITHUB_ACCESS_TOKEN }}
          
      - name: Setup repo with DRM
        run: ./scripts/setup-repo-drm.sh
        env:
          BUILD_CONTEXT: ci
          
      - name: Build non-Carthage 3rd party dependencies
        run: ./scripts/build-3rd-party-dependencies.sh
        env:
          BUILD_CONTEXT: ci
          
      - name: List available simulators for debugging
        run: xcrun simctl list devices available | grep iPhone | head -10
        
      - name: Run Palace unit tests
        id: tests
        run: ./scripts/xcode-test-optimized.sh
        env:
          BUILD_CONTEXT: ci
        continue-on-error: true
          
      - name: Find Test Results
        if: always()
        id: find_results
        run: |
          echo "Looking for xcresult bundles..."
          
          # Check current directory
          if [ -d "TestResults.xcresult" ]; then
            echo "Found: ./TestResults.xcresult"
            echo "path=TestResults.xcresult" >> $GITHUB_OUTPUT
            echo "found=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Search in common locations
          FOUND=$(find . -name "*.xcresult" -type d 2>/dev/null | head -1)
          if [ -n "$FOUND" ]; then
            echo "Found: $FOUND"
            echo "path=$FOUND" >> $GITHUB_OUTPUT
            echo "found=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Search in DerivedData
          FOUND=$(find ~/Library/Developer/Xcode/DerivedData -name "*.xcresult" -type d 2>/dev/null | head -1)
          if [ -n "$FOUND" ]; then
            echo "Found in DerivedData: $FOUND"
            cp -r "$FOUND" ./TestResults.xcresult
            echo "path=TestResults.xcresult" >> $GITHUB_OUTPUT
            echo "found=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "No xcresult found"
          echo "found=false" >> $GITHUB_OUTPUT
          
      - name: Parse Test Results
        if: always()
        id: parse_results
        run: |
          RESULT_PATH="${{ steps.find_results.outputs.path }}"
          
          # Initialize defaults
          echo "tests=0" >> $GITHUB_OUTPUT
          echo "passed=0" >> $GITHUB_OUTPUT
          echo "failed=0" >> $GITHUB_OUTPUT
          echo "skipped=0" >> $GITHUB_OUTPUT
          echo "duration=unknown" >> $GITHUB_OUTPUT
          echo "failed_tests=" >> $GITHUB_OUTPUT
          
          if [ "${{ steps.find_results.outputs.found }}" != "true" ] || [ ! -d "$RESULT_PATH" ]; then
            echo "No results to parse"
            exit 0
          fi
          
          # Get JSON from xcresult
          RESULT_JSON=$(xcrun xcresulttool get --path "$RESULT_PATH" --format json 2>/dev/null || echo "{}")
          
          # Parse metrics
          TESTS=$(echo "$RESULT_JSON" | python3 -c "import json,sys; d=json.load(sys.stdin); print(d.get('metrics',{}).get('testsCount',{}).get('_value','0'))" 2>/dev/null || echo "0")
          FAILURES=$(echo "$RESULT_JSON" | python3 -c "import json,sys; d=json.load(sys.stdin); print(d.get('metrics',{}).get('testsFailedCount',{}).get('_value','0'))" 2>/dev/null || echo "0")
          SKIPPED=$(echo "$RESULT_JSON" | python3 -c "import json,sys; d=json.load(sys.stdin); print(d.get('metrics',{}).get('testsSkippedCount',{}).get('_value','0'))" 2>/dev/null || echo "0")
          
          if [ "$TESTS" != "0" ] && [ "$TESTS" != "" ]; then
            PASSED=$((TESTS - FAILURES - SKIPPED))
            echo "tests=$TESTS" >> $GITHUB_OUTPUT
            echo "passed=$PASSED" >> $GITHUB_OUTPUT
            echo "failed=$FAILURES" >> $GITHUB_OUTPUT
            echo "skipped=$SKIPPED" >> $GITHUB_OUTPUT
          fi
          
          # Extract failed test names using xcresulttool
          if [ "$FAILURES" != "0" ] && [ "$FAILURES" != "" ]; then
            echo "Extracting failed test names..."
            
            # Get test plan run summaries
            FAILED_TESTS=$(xcrun xcresulttool get --path "$RESULT_PATH" --format json 2>/dev/null | \
              python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    failed = []
    
    def find_failures(obj, path=''):
        if isinstance(obj, dict):
            # Check if this is a test with failure status
            if obj.get('testStatus', {}).get('_value') == 'Failure':
                name = obj.get('name', {}).get('_value', '')
                if name:
                    failed.append(name)
            # Recurse
            for k, v in obj.items():
                find_failures(v, f'{path}.{k}')
        elif isinstance(obj, list):
            for item in obj:
                find_failures(item, path)
    
    find_failures(data)
    print('\n'.join(failed[:20]))  # Limit to 20 failures
except:
    pass
" 2>/dev/null || echo "")
            
            # URL-encode for multiline output
            if [ -n "$FAILED_TESTS" ]; then
              echo "failed_tests<<EOF" >> $GITHUB_OUTPUT
              echo "$FAILED_TESTS" >> $GITHUB_OUTPUT
              echo "EOF" >> $GITHUB_OUTPUT
            fi
          fi
          
      - name: Generate Test Report
        if: always()
        id: report
        run: |
          mkdir -p test-report
          REPORT_FILE="test-report/TEST_RESULTS.md"
          
          # Header
          echo "# üß™ Palace iOS Unit Test Results" > "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "**Run:** $(date '+%Y-%m-%d %H:%M:%S UTC')" >> "$REPORT_FILE"
          echo "**Commit:** ${{ github.sha }}" >> "$REPORT_FILE"
          echo "**Branch:** ${{ github.head_ref || github.ref_name }}" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          
          TESTS="${{ steps.parse_results.outputs.tests }}"
          PASSED="${{ steps.parse_results.outputs.passed }}"
          FAILED="${{ steps.parse_results.outputs.failed }}"
          SKIPPED="${{ steps.parse_results.outputs.skipped }}"
          
          # Summary box
          echo "## Summary" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          
          if [ "$TESTS" != "0" ] && [ "$TESTS" != "" ]; then
            if [ "$FAILED" = "0" ]; then
              echo "### ‚úÖ ALL TESTS PASSED" >> "$REPORT_FILE"
            else
              echo "### ‚ùå TESTS FAILED" >> "$REPORT_FILE"
            fi
            echo "" >> "$REPORT_FILE"
            echo "| Metric | Count |" >> "$REPORT_FILE"
            echo "|--------|-------|" >> "$REPORT_FILE"
            echo "| Total Tests | $TESTS |" >> "$REPORT_FILE"
            echo "| ‚úÖ Passed | $PASSED |" >> "$REPORT_FILE"
            echo "| ‚ùå Failed | $FAILED |" >> "$REPORT_FILE"
            if [ "$SKIPPED" != "0" ]; then
              echo "| ‚è≠Ô∏è Skipped | $SKIPPED |" >> "$REPORT_FILE"
            fi
          else
            if [ "${{ steps.tests.outcome }}" = "success" ]; then
              echo "### ‚úÖ ALL TESTS PASSED" >> "$REPORT_FILE"
            else
              echo "### ‚ùå TESTS FAILED" >> "$REPORT_FILE"
            fi
            echo "" >> "$REPORT_FILE"
            echo "_Could not parse detailed metrics from xcresult_" >> "$REPORT_FILE"
          fi
          
          # Failed tests section
          FAILED_TESTS="${{ steps.parse_results.outputs.failed_tests }}"
          if [ -n "$FAILED_TESTS" ]; then
            echo "" >> "$REPORT_FILE"
            echo "## Failed Tests" >> "$REPORT_FILE"
            echo "" >> "$REPORT_FILE"
            echo '```' >> "$REPORT_FILE"
            echo "$FAILED_TESTS" >> "$REPORT_FILE"
            echo '```' >> "$REPORT_FILE"
            echo "" >> "$REPORT_FILE"
            echo "_Download the **test-results** artifact and open in Xcode for full failure details._" >> "$REPORT_FILE"
          fi
          
          # Snapshot failures
          SNAPSHOT_COUNT="${{ steps.snapshots.outputs.count }}"
          if [ "$SNAPSHOT_COUNT" != "0" ] && [ "$SNAPSHOT_COUNT" != "" ]; then
            echo "" >> "$REPORT_FILE"
            echo "## üì∏ Snapshot Failures ($SNAPSHOT_COUNT)" >> "$REPORT_FILE"
            echo "" >> "$REPORT_FILE"
            echo "Download the **snapshot-failures** artifact to view difference images." >> "$REPORT_FILE"
            echo "" >> "$REPORT_FILE"
            if [ -d "snapshot-failures" ]; then
              ls -1 snapshot-failures/*.png 2>/dev/null | head -10 | while read -r f; do
                echo "- \`$(basename "$f")\`" >> "$REPORT_FILE"
              done
            fi
          fi
          
          # Artifacts section
          echo "" >> "$REPORT_FILE"
          echo "---" >> "$REPORT_FILE"
          echo "## üì¶ Artifacts" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "- **test-results** - Full .xcresult bundle (open in Xcode for detailed analysis)" >> "$REPORT_FILE"
          echo "- **test-report** - This human-readable summary" >> "$REPORT_FILE"
          if [ "$SNAPSHOT_COUNT" != "0" ] && [ "$SNAPSHOT_COUNT" != "" ]; then
            echo "- **snapshot-failures** - PNG images showing visual differences" >> "$REPORT_FILE"
          fi
          
          echo "" >> "$REPORT_FILE"
          echo "### How to View in Xcode" >> "$REPORT_FILE"
          echo "1. Download **test-results** artifact" >> "$REPORT_FILE"
          echo "2. Unzip the downloaded file" >> "$REPORT_FILE"
          echo "3. Double-click the .xcresult bundle to open in Xcode" >> "$REPORT_FILE"
          echo "4. Navigate to failed tests to see stack traces and failure reasons" >> "$REPORT_FILE"
          
          cat "$REPORT_FILE"
          
      - name: Generate GitHub Step Summary
        if: always()
        run: |
          TESTS="${{ steps.parse_results.outputs.tests }}"
          PASSED="${{ steps.parse_results.outputs.passed }}"
          FAILED="${{ steps.parse_results.outputs.failed }}"
          SKIPPED="${{ steps.parse_results.outputs.skipped }}"
          
          echo "## üß™ Palace Unit Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$TESTS" != "0" ] && [ "$TESTS" != "" ]; then
            if [ "$FAILED" = "0" ]; then
              echo "### ‚úÖ ALL TESTS PASSED" >> $GITHUB_STEP_SUMMARY
            else
              echo "### ‚ùå SOME TESTS FAILED" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Total Tests | **$TESTS** |" >> $GITHUB_STEP_SUMMARY
            echo "| ‚úÖ Passed | **$PASSED** |" >> $GITHUB_STEP_SUMMARY
            echo "| ‚ùå Failed | **$FAILED** |" >> $GITHUB_STEP_SUMMARY
            if [ "$SKIPPED" != "0" ]; then
              echo "| ‚è≠Ô∏è Skipped | **$SKIPPED** |" >> $GITHUB_STEP_SUMMARY
            fi
          else
            if [ "${{ steps.tests.outcome }}" = "success" ]; then
              echo "### ‚úÖ ALL TESTS PASSED" >> $GITHUB_STEP_SUMMARY
            else
              echo "### ‚ùå TESTS FAILED" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          # Failed tests
          FAILED_TESTS="${{ steps.parse_results.outputs.failed_tests }}"
          if [ -n "$FAILED_TESTS" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Failed Tests" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "$FAILED_TESTS" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Collect Snapshot Failures
        if: always()
        id: snapshots
        run: |
          mkdir -p snapshot-failures
          
          echo "Searching for snapshot failures..."
          
          # Search in multiple locations where SnapshotTesting puts failure images
          
          # 1. Simulator temp directories (where SnapshotTesting writes new snapshots)
          echo "Checking simulator temp directories..."
          find /Users/runner/Library/Developer/CoreSimulator -name "*.png" -path "*tmp*" -type f 2>/dev/null | while read -r file; do
            echo "Found: $file"
            cp "$file" snapshot-failures/ 2>/dev/null || true
          done
          
          # 2. App container tmp directories
          echo "Checking app containers..."
          find /Users/runner/Library/Developer/CoreSimulator/Devices -path "*/tmp/*.png" -type f 2>/dev/null | while read -r file; do
            echo "Found: $file"
            cp "$file" snapshot-failures/ 2>/dev/null || true
          done
          
          # 3. Any Failures directories in DerivedData
          echo "Checking DerivedData..."
          find ~/Library/Developer/Xcode/DerivedData -name "*.png" -path "*Failures*" -type f 2>/dev/null | while read -r file; do
            echo "Found: $file"
            cp "$file" snapshot-failures/ 2>/dev/null || true
          done
          
          # 4. Check workspace for any snapshot test output
          echo "Checking workspace..."
          find . -name "*.png" -path "*tmp*" -type f 2>/dev/null | while read -r file; do
            echo "Found: $file"
            cp "$file" snapshot-failures/ 2>/dev/null || true
          done
          
          # 5. Check for __Snapshots__ directories with recent modifications
          echo "Checking for recent snapshot changes..."
          if [ -d "TestResults.xcresult" ]; then
            find . -path "*__Snapshots__*" -name "*.png" -newer TestResults.xcresult -type f 2>/dev/null | while read -r file; do
              echo "Found recently modified: $file"
              cp "$file" snapshot-failures/ 2>/dev/null || true
            done
          fi
          
          # Count what we found
          COUNT=$(ls -1 snapshot-failures/*.png 2>/dev/null | wc -l | tr -d ' ')
          echo "Total snapshot files found: $COUNT"
          
          if [ "$COUNT" -gt "0" ]; then
            echo "found=true" >> $GITHUB_OUTPUT
            echo "count=$COUNT" >> $GITHUB_OUTPUT
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üì∏ Snapshot Failures ($COUNT)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Download **snapshot-failures** artifact to view diff images" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            ls -1 snapshot-failures/*.png 2>/dev/null | head -15 | while read -r f; do
              echo "- \`$(basename "$f")\`" >> $GITHUB_STEP_SUMMARY
            done
          else
            echo "found=false" >> $GITHUB_OUTPUT
            echo "count=0" >> $GITHUB_OUTPUT
          fi
          
      - name: Add Artifact Links to Summary
        if: always()
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "### üì¶ Download Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Artifact | Description |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-------------|" >> $GITHUB_STEP_SUMMARY
          echo "| **test-report** | üìÑ Human-readable test summary (Markdown) |" >> $GITHUB_STEP_SUMMARY
          echo "| **test-results** | üìä Full xcresult bundle (open in Xcode) |" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.snapshots.outputs.found }}" = "true" ]; then
            echo "| **snapshot-failures** | üñºÔ∏è PNG diff images from failed snapshots |" >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Upload Test Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-report
          path: test-report/
          retention-days: 14
          if-no-files-found: ignore
          
      - name: Upload Snapshot Failures
        if: steps.snapshots.outputs.found == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: snapshot-failures
          path: snapshot-failures/
          retention-days: 14
          if-no-files-found: ignore
          
      - name: Upload Test Results
        if: steps.find_results.outputs.found == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: ${{ steps.find_results.outputs.path }}
          retention-days: 14
          if-no-files-found: ignore
          
      - name: Post PR Comment with Results
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const tests = '${{ steps.parse_results.outputs.tests }}';
            const passed = '${{ steps.parse_results.outputs.passed }}';
            const failed = '${{ steps.parse_results.outputs.failed }}';
            const skipped = '${{ steps.parse_results.outputs.skipped }}';
            const testOutcome = '${{ steps.tests.outcome }}';
            const failedTests = `${{ steps.parse_results.outputs.failed_tests }}`;
            const snapshotCount = '${{ steps.snapshots.outputs.count }}';
            const runUrl = `${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID}`;
            
            let body = '## üß™ Unit Test Results\n\n';
            
            // Status badge
            if (tests !== '0' && tests !== '') {
              if (failed === '0') {
                body += `### ‚úÖ ALL TESTS PASSED\n\n`;
              } else {
                body += `### ‚ùå ${failed} TEST${failed === '1' ? '' : 'S'} FAILED\n\n`;
              }
              
              body += `| Metric | Count |\n`;
              body += `|--------|-------|\n`;
              body += `| Total | **${tests}** |\n`;
              body += `| ‚úÖ Passed | **${passed}** |\n`;
              body += `| ‚ùå Failed | **${failed}** |\n`;
              if (skipped !== '0') {
                body += `| ‚è≠Ô∏è Skipped | **${skipped}** |\n`;
              }
            } else {
              if (testOutcome === 'success') {
                body += `### ‚úÖ ALL TESTS PASSED\n\n`;
              } else {
                body += `### ‚ùå TESTS FAILED\n\n`;
              }
            }
            
            // Failed test names
            if (failedTests && failedTests.trim()) {
              body += `\n<details>\n<summary>Failed Tests (click to expand)</summary>\n\n`;
              body += '```\n' + failedTests.trim() + '\n```\n';
              body += `</details>\n`;
            }
            
            // Snapshot failures
            if (snapshotCount && snapshotCount !== '0') {
              body += `\n### üì∏ Snapshot Failures: ${snapshotCount}\n`;
              body += `Download the **snapshot-failures** artifact to view visual differences.\n`;
            }
            
            // Artifacts link
            body += `\n---\n`;
            body += `üì¶ **[View Artifacts & Full Details](${runUrl})**\n\n`;
            body += `| Artifact | Description |\n`;
            body += `|----------|-------------|\n`;
            body += `| test-report | üìÑ Human-readable summary |\n`;
            body += `| test-results | üìä Full xcresult (open in Xcode) |\n`;
            if (snapshotCount && snapshotCount !== '0') {
              body += `| snapshot-failures | üñºÔ∏è Visual diff images |\n`;
            }
            
            // Find and update existing comment or create new one
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });
            
            const botComment = comments.find(c => 
              c.user.type === 'Bot' && 
              c.body.includes('üß™ Unit Test Results')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }
          
      - name: Fail if tests failed
        if: steps.tests.outcome == 'failure'
        run: exit 1
